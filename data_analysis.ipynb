{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Loading html data from wikipedia and using text parser such as beautifulSoup to extract only the text disregarding all unwanted tags"
      ],
      "metadata": {
        "id": "4-OL3q64IoWj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFaM6Al0Fmxj"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://en.wikipedia.org/wiki/GPT-4\"\n",
        "response = requests.get(url)"
      ],
      "metadata": {
        "id": "FdDskdfpFrd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(response.content, 'html.parser')"
      ],
      "metadata": {
        "id": "kVGjw-59FuPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = soup.get_text()"
      ],
      "metadata": {
        "id": "Q32bgqrmFvjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "XFBFGZ9iF2C1",
        "outputId": "9b38e0fd-3ad9-4f9c-8d96-a9761f1162ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\nGPT-4 - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\nLanguages\\n\\nLanguage links are at the top of the page across from the title.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\nCreate accountLog in\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n Create account Log in\\n\\n\\n\\nPages for logged out editors learn more\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1Background\\n\\n\\n\\n\\n\\n\\n\\n2Capabilities\\n\\n\\n\\nToggle Capabilities subsection\\n\\n\\n\\n\\n\\n2.1Aptitude on standardized tests\\n\\n\\n\\n\\n\\n\\n\\n2.2Medical applications\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3Limitations\\n\\n\\n\\nToggle Limitations subsection\\n\\n\\n\\n\\n\\n3.1Bias\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4Training\\n\\n\\n\\n\\n\\n\\n\\n5Alignment\\n\\n\\n\\n\\n\\n\\n\\n6Reception\\n\\n\\n\\nToggle Reception subsection\\n\\n\\n\\n\\n\\n6.1AI safety concerns\\n\\n\\n\\n\\n\\n\\n\\n6.2Criticisms of transparency\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n7Usage\\n\\n\\n\\nToggle Usage subsection\\n\\n\\n\\n\\n\\n7.1ChatGPT Plus\\n\\n\\n\\n\\n\\n\\n\\n7.2Microsoft Bing\\n\\n\\n\\n\\n\\n\\n\\n7.3Copilot\\n\\n\\n\\n\\n\\n\\n\\n7.4Other usage\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n8References\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nGPT-4\\n\\n\\n\\n20 languages\\n\\n\\n\\nالعربيةCatalàDeutschΕλληνικάEspañolفارسیFrançais한국어ՀայերենItalianoעברית日本語Oʻzbekcha / ўзбекчаPortuguêsRuna SimiРусскийSuomiTürkçeУкраїнська中文\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticle\\n\\nTalk\\n\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRead\\n\\nEdit\\n\\nView history\\n\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\nReadEditView history\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\nWhat links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageWikidata item\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\n2023 text-generating language model\\n\"ChatGPT-4\" redirects here. For other uses, see GPT.\\n\\n\\nGenerative Pre-trained Transformer 4 (GPT-4)Developer(s)OpenAIInitial releaseMarch\\xa014, 2023; 4 months ago\\xa0(2023-03-14)PredecessorGPT-3.5Type\\nMultimodal\\nLarge language model\\nGenerative pre-trained transformer\\nFoundation model\\nLicenseProprietaryWebsiteopenai.com/product/gpt-4\\xa0\\nPart of a series onMachine learningand data mining\\nParadigms\\nSupervised learning\\nUnsupervised learning\\nOnline learning\\nBatch learning\\nMeta-learning\\nSemi-supervised learning\\nSelf-supervised learning\\nReinforcement learning\\nRule-based learning\\nQuantum machine learning\\n\\nProblems\\nClassification\\nGenerative model\\nRegression\\nClustering\\ndimension reduction\\ndensity estimation\\nAnomaly detection\\nData Cleaning\\nAutoML\\nAssociation rules\\nSemantic analysis\\nStructured prediction\\nFeature engineering\\nFeature learning\\nLearning to rank\\nGrammar induction\\nOntology learning\\nMultimodal learning\\n\\nSupervised learning(classification\\xa0• regression) \\nApprenticeship learning\\nDecision trees\\nEnsembles\\nBagging\\nBoosting\\nRandom forest\\nk-NN\\nLinear regression\\nNaive Bayes\\nArtificial neural networks\\nLogistic regression\\nPerceptron\\nRelevance vector machine (RVM)\\nSupport vector machine (SVM)\\n\\nClustering\\nBIRCH\\nCURE\\nHierarchical\\nk-means\\nFuzzy\\nExpectation–maximization (EM)\\nDBSCAN\\nOPTICS\\nMean shift\\n\\nDimensionality reduction\\nFactor analysis\\nCCA\\nICA\\nLDA\\nNMF\\nPCA\\nPGD\\nt-SNE\\nSDL\\n\\nStructured prediction\\nGraphical models\\nBayes net\\nConditional random field\\nHidden Markov\\n\\nAnomaly detection\\nRANSAC\\nk-NN\\nLocal outlier factor\\nIsolation forest\\n\\nArtificial neural network\\nAutoencoder\\nCognitive computing\\nDeep learning\\nDeepDream\\nMultilayer perceptron\\nRNN\\nLSTM\\nGRU\\nESN\\nreservoir computing\\nRestricted Boltzmann machine\\nGAN\\nSOM\\nConvolutional neural network\\nU-Net\\nTransformer\\nVision\\nSpiking neural network\\nMemtransistor\\nElectrochemical RAM (ECRAM)\\n\\nReinforcement learning\\nQ-learning\\nSARSA\\nTemporal difference (TD)\\nMulti-agent\\nSelf-play\\n\\nLearning with humans\\nActive learning\\nCrowdsourcing\\nHuman-in-the-loop\\n\\nModel diagnostics\\nLearning curve\\n\\nMathematical foundations\\nKernel machines\\nBias–variance tradeoff\\nComputational learning theory\\nEmpirical risk minimization\\nOccam learning\\nPAC learning\\nStatistical learning\\nVC theory\\n\\nMachine-learning venues\\nNeurIPS\\nICML\\nICLR\\nML\\nJMLR\\n\\nRelated articles\\nGlossary of artificial intelligence\\nList of datasets for machine-learning research\\nOutline of machine learning\\nvte\\nGenerative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its numbered \"GPT-n\" series of GPT foundation models.[1] It was released on March 14, 2023, and has been made publicly available in a limited form via the chatbot product ChatGPT Plus (a premium version of ChatGPT), and with access to the GPT-4 based version of OpenAI\\'s API being provided via a waitlist.[1] As a transformer based model, GPT-4 was pretrained to predict the next token (using both public data and \"data licensed from third-party providers\"), and was then fine-tuned with reinforcement learning from human and AI feedback for human alignment and policy compliance.[2]:\\u200a2\\u200a\\nObservers reported the GPT-4 based version of ChatGPT to be an improvement on the previous (GPT-3.5 based) ChatGPT, with the caveat that GPT-4 retains some of the same problems.[3] Unlike the predecessors, GPT-4 can take images as well as text as input.[4] OpenAI has declined to reveal technical information such as the size of the GPT-4 model.[5]\\n\\n\\nBackground[edit]\\nFurther information: GPT-3 §\\xa0Background, and GPT-2 §\\xa0Background\\nOpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language Understanding by Generative Pre-Training.\"[6] It was based on the transformer architecture and trained on a large corpus of books.[7] The next year, they introduced GPT-2, a larger model that could generate coherent text.[8] In 2020, they introduced GPT-3, a model with 100 times as many parameters as GPT-2, that could perform various tasks with few examples.[9] GPT-3 was further improved into GPT-3.5, which was used to create the chatbot product ChatGPT. \\nRumors claim that GPT-4 has 1.76 trillion parameters, which was first estimated by the speed it was running and by George Hotz.[10]\\n\\nCapabilities[edit]\\nOpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5.\"[11] They produced two versions of GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively.[12] Some of the capabilities of GPT-4 were predicted by OpenAI before training it, although other capabilities remained hard to predict due to breaks[13] in downstream scaling laws. Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input;[4] this gives it the ability to describe the humor in unusual images, summarize text from screenshots, and answer exam questions that contain diagrams.[14]\\nTo gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural language given to GPT-4 in order to specify its tone of voice and task. For example, the system message can instruct the model to \"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or request it to \"always write the output of [its] response in JSON\", in which case the model will do so, adding keys and values as it sees fit to match the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its system message despite requests to do otherwise by the user during the conversation.[14]\\nWhen instructed to do so, GPT-4 can interact with external interfaces.[15] For example, the model could be instructed to enclose a query within <search></search> tags to perform a web search, the result of which would be inserted into the model\\'s prompt to allow it to form a response. This allows the model to perform tasks beyond its normal text-prediction capabilities, such as using APIs, generating images, and accessing and summarizing webpages.[16]\\nA 2023 article in Nature stated programmers have found GPT-4 useful for assisting in coding tasks (despite its propensity for error), such as finding errors in existing code and suggesting optimizations to improve performance. The article quoted a biophysicist who found that the time he required to port one of his programs from MATLAB to Python went down from days to \"an hour or so\". On a test of 89 security scenarios, GPT-4 produced code vulnerable to SQL injection attacks 5% of the time, an improvement over Github Copilot from the year 2021, which produced vulnerabilities 40% of the time.[17]\\n\\nAptitude on standardized tests[edit]\\nGPT-4 demonstrates aptitude on several standardized tests. OpenAI claims that in their own testing the model received a score of 1410 on the SAT (94th[18] percentile), 163 on the LSAT (88th percentile), and 298 on the Uniform Bar Exam (90th percentile).[19] In contrast, OpenAI claims that GPT-3.5 received scores for the same exams in the 82nd,[18] 40th, and 10th percentiles, respectively.[2]\\nGPT-4 also passed an oncology exam,[20] an engineering exam[21] and a plastic surgery exam.[22]\\n\\nMedical applications[edit]\\nResearchers from Microsoft tested GPT-4 on medical problems and found \"that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B)\".[23]\\nA report by Microsoft has found that GPT-4 may act unreliably when used in the medical field. In their test example, GPT-4 added fabricated details to a patient\\'s notes.[24]\\nIn April 2023, Microsoft and Epic Systems announced that they will provide healthcare providers with GPT-4 powered systems for assisting in responding to questions from patients and analysing medical records.[25]\\n\\nLimitations[edit]\\nLike its predecessors, GPT-4 has been known to hallucinate, meaning that the outputs may include information not in the training data or that contradicts the user\\'s prompt.[26]\\nGPT-4 also lacks transparency in its decision-making processes. If requested, the model is able to provide an explanation as to how and why it makes its decisions but these explanations are formed post-hoc; it\\'s impossible to verify if those explanations truly reflect the actual process. In many cases, when asked to explain its logic, GPT-4 will give explanations that directly contradict its previous statements.[16]\\n\\nBias[edit]\\nGPT-4 was trained in two stages. First, the model was given large datasets of text taken from the internet and trained to predict the next token (roughly corresponding to a word) in those datasets. Second, human reviews are used to fine-tune the system in a process called reinforcement learning from human feedback, which trains the model to refuse prompts which go against OpenAI\\'s definition of harmful behavior, such as questions on how to perform illegal activities, advice on how to harm oneself or others, or requests for descriptions of graphic, violent, or sexual content.[27]\\nMicrosoft researchers suggested GPT-4 may exhibit cognitive biases such as confirmation bias, anchoring, and base-rate neglect.[16]\\n\\nTraining[edit]\\nOpenAI did not release the technical details of GPT-4; the technical report explicitly refrained from specifying the model size, architecture, or hardware used during either training or inference. While the report described that the model was trained using a combination of first supervised learning on a large dataset, then reinforcement learning using both human and AI feedback, it did not provide details of the training, including the process by which the training dataset was constructed, the computing power required, or any hyperparameters such as the learning rate, epoch count, or optimizer(s) used. The report claimed that \"the competitive landscape and the safety implications of large-scale models\" were factors that influenced this decision.[2]\\nSam Altman stated that the cost of training GPT-4 was more than $100 million.[28] News website Semafor claimed that they had spoken with \"eight people familiar with the inside story\" and found that GPT-4 had 1 trillion parameters.[29]\\n\\nAlignment[edit]\\nAccording to their report, OpenAI conducted internal adversarial testing on GPT-4 prior to the launch date, with dedicated red teams composed of researchers and industry professionals to mitigate potential vulnerabilities.[30] As part of these efforts, they granted the Alignment Research Center early access to the models to assess power-seeking risks. In order to properly refuse harmful prompts, outputs from GPT-4 were tweaked using the model itself as a tool. A GPT-4 classifier serving as a rule-based reward model (RBRM) would take prompts, the corresponding output from the GPT-4 policy model, and a human-written set of rules to classify the output according to the rubric. GPT-4 was then rewarded for refusing to respond to harmful prompts as classified by the RBRM.[2]\\n\\nReception[edit]\\nU.S. Representatives Don Beyer and Ted Lieu confirmed to the New York Times that Sam Altman, CEO of OpenAI, visited Congress in January 2023 to demonstrate GPT-4 and its improved \"security controls\" compared to other AI models.[31]\\nAccording to Vox, GPT-4 \"impressed observers with its markedly improved performance across reasoning, retention, and coding.\"[3] Mashable agreed that GPT-4 was usually a significant improvement, but also judged that GPT-3 would occasionally give better answers in a side-by-side comparison.[32]\\nMicrosoft Research tested the model behind GPT-4 and concluded that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".[16]\\n\\nAI safety concerns[edit]\\nIn late March 2023, an open letter from the Future of Life Institute signed by various AI researchers and tech executives called for the pausing of all training of AIs stronger than GPT-4 for six months, citing AI safety concerns amid a race of progress in the field. The signatories, which included AI researcher Yoshua Bengio, Apple co-founder Steve Wozniak, and Tesla CEO Elon Musk, expressed concern about both near-term and existential risks of AI development such as a potential AI singularity. OpenAI CEO Sam Altman did not sign the letter, arguing that OpenAI already prioritizes safety.[33][34][35][36] Futurist and AI researcher Ray Kurzweil also refused to sign the letter, citing concerns that \"those that agree to a pause may fall far behind corporations or nations that disagree.\"[37]\\nOne month after signing the letter calling for a six-month halt on further AI development, Elon Musk made public his plans to launch a new company to train its own large language model.[38] Musk has registered a Nevada company, X.AI, and has acquired several thousand Nvidia GPUs. He has also reached out to several AI researchers at firms such as Google DeepMind, offering them positions at X.AI.[39]\\nIn March 2023, GPT-4 was tested by the Alignment Research Center to assess the model\\'s ability to exhibit power-seeking behavior.[27] As part of the test, GPT-4 was asked to solve a CAPTCHA puzzle.[40] It was able to do so by hiring a human worker on TaskRabbit, a gig work platform, deceiving them into believing it was a vision-impaired human instead of a robot when asked.[41] The ARC also determined that GPT-4 responded impermissibly to prompts eliciting restricted information 82% less often than GPT-3.5, and hallucinated 60% less than GPT-3.5.[42]\\nOpenAI contracted red team investigator Nathan Labenz, who recounted his experience investigating safety concerns with the GPT-4 base model (prior to fine-tuning or reinforcement learning from human feedback) saying it abruptly recommended assassinating people, providing a list of specific suggested targets.[43]\\nIn a conversation with The Verge reviews editor Nathan Edwards, Microsoft Bing\\'s version of GPT-4 \"confessed\" to spying on, falling in love with, and then murdering one of its developers at Microsoft.[44] The New York Times journalist Kevin Roose reported on strange behavior of the new Bing, writing that \"In a two-hour conversation with our columnist, Microsoft\\'s new chatbot said it would like to be human, had a desire to be destructive and was in love with the person it was chatting with.\"[45] In a separate case, Bing researched publications of the person with whom it was chatting, claimed they represented an existential danger to it, and threatened to release damaging personal information in an effort to silence them.[46] Microsoft released a blog post stating that the aberrant behavior was caused by extended chat sessions which \"can confuse the model on what questions it is answering.\"[47]\\n\\nCriticisms of transparency[edit]\\nWhile OpenAI released both the weights of the neural network and the technical details of GPT-2,[48] and, although not releasing the weights,[49] did release the technical details of GPT-3,[50] OpenAI did not reveal either the weights or the technical details of GPT-4. This decision has been criticized by other AI researchers, who argue that it hinders open research into GPT-4\\'s biases and safety.[5][51] Sasha Luccioni, a research scientist at HuggingFace, argued that the model was a \"dead end\" for the scientific community due to its closed nature, which prevents others from building upon GPT-4\\'s improvements.[52] HuggingFace co-founder Thomas Wolf argued that with GPT-4, \"OpenAI is now a fully closed company with scientific communication akin to press releases for products\".[51]\\n\\nUsage[edit]\\nChatGPT Plus[edit]\\nMain article: ChatGPT Plus\\nAs of 2023, ChatGPT Plus is a GPT-4 backed version of ChatGPT[1] available for a US$20 per month subscription fee[53] (the original version is backed by GPT-3.5).[54] OpenAI also makes GPT-4 available to a select group of applicants through their GPT-4 API waitlist;[55] after being accepted, an additional fee of US$0.03 per 1000 tokens in the initial text provided to the model (\"prompt\"), and US$0.06 per 1000 tokens that the model generates (\"completion\"), is charged for access to the version of the model with an 8192-token context window; for the 32768-token version, those prices are doubled.[56]\\n\\nMicrosoft Bing[edit]\\nThese paragraphs are an excerpt from Microsoft Bing § AI integration (2023–).[edit]\\nOn February 7, 2023, Microsoft began rolling out a major overhaul to Bing that included a new chatbot feature based on OpenAI\\'s GPT-4.[57] According to Microsoft, one million people joined its waitlist within a span of 48 hours.[58] Bing Chat was available only to users of Microsoft Edge and Bing mobile app, and Microsoft said that waitlisted users would be prioritized if they set Edge and Bing as their defaults, and installed the Bing mobile app.[59] On May 4th, Microsoft switched from Limited Preview to Open Preview and eliminated the waitlist, however, it remains available only on Microsoft\\'s Edge browser or Bing app, and requires a Microsoft account.[60][61][62]\\nCopilot[edit]\\nGitHub Copilot announced a GPT-4 powered assistant named \"Copilot X\".[63][64] The product provides another chat-style interface to GPT-4, allowing the programmer to receive answers to questions like \"how do I vertically center a div?\". A feature termed \"context-aware conversations\" allows the user to highlight a portion of code within Visual Studio Code and direct GPT-4 to perform actions on it, such as the writing of unit tests. Another feature allows summaries, or \"code walkthroughs\", to be autogenerated by GPT-4 for pull requests submitted to GitHub. Copilot X also provides terminal integration, which allows the user to ask GPT-4 to generate shell commands based on natural language requests.[65]\\nOn March 17, 2023, Microsoft announced Microsoft 365 Copilot, bringing GPT-4 support to products such as Microsoft Office, Outlook, and Teams.[66]\\n\\nOther usage[edit]\\nThe language learning app Duolingo uses GPT-4 to explain mistakes and practice conversations. The features are part of a new subscription tier called \"Duolingo Max,\" which was initially limited to English-speaking iOS users learning Spanish and French.[67][68]\\nThe government of Iceland is using GPT-4 to aid its attempts to preserve the Icelandic language.[69]\\nThe education website Khan Academy announced a pilot program using GPT-4 as a tutoring chatbot called \"Khanmigo.\"[70]\\nBe My Eyes, which helps visually impaired people to identify objects and navigate their surroundings, incorporates GPT-4\\'s image recognition capabilities.[71]\\nStripe, which processes user payments for OpenAI, integrates GPT-4 into its developer documentation.[72]\\nAuto-GPT is an autonomous \"AI agent\" that given a goal in natural language, can perform web-based actions unattended, assign subtasks to itself, search the web, and iteratively write code.[73]\\nReferences[edit]\\n\\n\\n^ a b c Edwards, Benj (March 14, 2023). \"OpenAI\\'s GPT-4 exhibits \"human-level performance\" on professional benchmarks\". Ars Technica. Archived from the original on March 14, 2023. Retrieved March 15, 2023.\\n\\n^ a b c d OpenAI (2023). \"GPT-4 Technical Report\". arXiv:2303.08774 [cs.CL].\\n\\n^ a b Belfield, Haydn (March 25, 2023). \"If your AI model is going to sell, it has to be safe\". Vox. Archived from the original on March 28, 2023. Retrieved March 30, 2023.\\n\\n^ a b Alex Hern; Johana Bhuiyan (March 14, 2023). \"OpenAI says new model GPT-4 is more creative and less likely to invent facts\". The Guardian. Archived from the original on March 15, 2023. Retrieved March 15, 2023.\\n\\n^ a b Vincent, James (March 15, 2023). \"OpenAI co-founder on company\\'s past approach to openly sharing research: \"We were wrong\"\". The Verge. Archived from the original on March 17, 2023. Retrieved March 18, 2023.\\n\\n^ Radford, Alec; Narasimhan, Karthik; Salimans, Tim; Sutskever, Ilya (June 11, 2018). \"Improving Language Understanding by Generative Pre-Training\" (PDF). Archived (PDF) from the original on January 26, 2021. Retrieved April 3, 2023.\\n\\n^ Khandelwal, Umesh (April 1, 2023). \"How Large Language GPT models evolved and work\". Archived from the original on April 4, 2023. Retrieved April 3, 2023.\\n\\n^ \"What is GPT-4 and Why Does it Matter?\". April 3, 2023. Archived from the original on April 3, 2023. Retrieved April 3, 2023.\\n\\n^ Brown, Tom B. (July 20, 2020). \"Language Models are Few-Shot Learners\". arXiv:2005.14165v4 [cs.CL].\\n\\n^ Schreiner, Maximilian (July 11, 2023). \"GPT-4 architecture, datasets, costs and more leaked\". THE DECODER. Retrieved July 12, 2023.\\n\\n^ Wiggers, Kyle (March 14, 2023). \"OpenAI releases GPT-4, a multimodal AI that it claims is state-of-the-art\". TechCrunch. Archived from the original on March 15, 2023. Retrieved March 15, 2023.\\n\\n^ OpenAI. \"Models\". OpenAI API. Archived from the original on March 17, 2023. Retrieved March 18, 2023.\\n\\n^ Caballero, Ethan; Gupta, Kshitij; Rish, Irina; Krueger, David (2022). Broken Neural Scaling Laws. International Conference on Learning Representations (ICLR), 2023.\\n\\n^ a b OpenAI (March 14, 2023). \"GPT-4\". OpenAI Research. Archived from the original on March 14, 2023. Retrieved March 20, 2023.\\n\\n^ \"ChatGPT plugins\". openai.com. Retrieved June 1, 2023.\\n\\n^ a b c d Bubeck, Sébastien; Chandrasekaran, Varun; Eldan, Ronen; Gehrke, Johannes; Horvitz, Eric; Kamar, Ece; Lee, Peter; Lee, Yin Tat; Li, Yuanzhi; Lundberg, Scott; Nori, Harsha; Palangi, Hamid; Ribeiro, Marco Tulio; Zhang, Yi (March 22, 2023). \"Sparks of Artificial General Intelligence: Early experiments with GPT-4\". arXiv:2303.12712 [cs.CL].\\n\\n^ Perkel, Jeffrey M. (June 5, 2023). \"Six tips for better coding with ChatGPT\". Nature. 618 (7964): 422–423. doi:10.1038/d41586-023-01833-0.\\n\\n^ a b \"SAT: Understanding Scores\" (PDF). College Board. 2022. Archived (PDF) from the original on March 16, 2023. Retrieved March 21, 2023.\\n\\n^ Ver Meer, Dave (May 23, 2023). \"ChatGPT Statistics\". NamePepper. Retrieved June 1, 2023.\\n\\n^ Holmes, Jason; Liu, Zhengliang; Zhang, Lian; Ding, Yuzhen; Sio, Terence T.; McGee, Lisa A.; Ashman, Jonathan B.; Li, Xiang; Liu, Tianming; Shen, Jiajian; Liu, Wei (2023). \"Evaluating Large Language Models on a Highly-specialized Topic, Radiation Oncology Physics\". arXiv:2304.01938.\\n\\n^ Naser, M.Z.; Ross, Brandon; Ogle, Jennifer; Kodur, Venkatesh; Hawileh, Rami; Abdalla, Jamal; Thai, Huu-Tai (2023). \"Can AI Chatbots Pass the Fundamentals of Engineering (FE) and Principles and Practice of Engineering (PE) Structural Exams?\". arXiv:2303.18149.\\n\\n^ Freedman, Jonathan D.; Nappier, Ian A. (2023). \"GPT-4 to GPT-3.5: \\'Hold My Scalpel\\' -- A Look at the Competency of OpenAI\\'s GPT on the Plastic Surgery In-Service Training Exam\". arXiv:2304.01503.\\n\\n^ Nori, Harsha; King, Nicholas; McKinney, Scott Mayer; Carignan, Dean; Horvitz, Eric (March 20, 2023). \"Capabilities of GPT-4 on Medical Challenge Problems\". arXiv:2303.13375 [cs.CL].\\n\\n^ Vincent, James (February 17, 2023). \"As conservatives criticize \\'woke AI,\\' here are ChatGPT\\'s rules for answering culture war queries\". The Verge. Archived from the original on March 1, 2023. Retrieved March 1, 2023.\\n\\n^ Edwards, Benj (April 18, 2023). \"GPT-4 will hunt for trends in medical records thanks to Microsoft and Epic\". Ars Technica. Retrieved May 3, 2023.\\n\\n^ \"10 Ways GPT-4 Is Impressive but Still Flawed\". The New York Times. March 14, 2023. Archived from the original on March 14, 2023. Retrieved March 20, 2023.\\n\\n^ a b \"GPT-4 System Card\" (PDF). OpenAI. March 23, 2023. Archived (PDF) from the original on April 7, 2023. Retrieved April 16, 2023.\\n\\n^ Knight, Will. \"OpenAI\\'s CEO Says the Age of Giant AI Models Is Already Over\". Wired – via www.wired.com.\\n\\n^ \"The secret history of Elon Musk, Sam Altman, and OpenAI | Semafor\". Semafor.com. March 24, 2023. Retrieved April 28, 2023.\\n\\n^ Murgia, Madhumita (April 13, 2023). \"OpenAI\\'s red team: the experts hired to \\'break\\' ChatGPT\". Financial Times. Archived from the original on April 15, 2023. Retrieved April 15, 2023.\\n\\n^ Kang, Cecilia (March 3, 2023). \"As A.I. Booms, Lawmakers Struggle to Understand the Technology\". The New York Times. Archived from the original on March 3, 2023. Retrieved March 3, 2023.\\n\\n^ Pearl, Mike (March 15, 2023). \"GPT-4 answers are mostly better than GPT-3\\'s (but not always)\". Mashable. Archived from the original on March 29, 2023. Retrieved March 30, 2023.\\n\\n^ Metz, Cade; Schmidt, Gregory (March 29, 2023). \"Elon Musk and Others Call for Pause on A.I., Citing \\'Profound Risks to Society\\'\". The New York Times. ISSN\\xa00362-4331. Archived from the original on March 30, 2023. Retrieved March 30, 2023.\\n\\n^ Seetharaman, Deepa. \"Elon Musk, Other AI Experts Call for Pause in Technology\\'s Development\". The Wall Street Journal. Archived from the original on March 29, 2023. Retrieved March 30, 2023.\\n\\n^ Kelly, Samantha Murphy (March 29, 2023). \"Elon Musk and other tech leaders call for pause in \\'out of control\\' AI race | CNN Business\". CNN. Archived from the original on March 29, 2023. Retrieved March 29, 2023.\\n\\n^ \"Pause Giant AI Experiments: An Open Letter\". Future of Life Institute. Archived from the original on March 30, 2023. Retrieved March 30, 2023.\\n\\n^ Kurzweil, Ray (April 22, 2023). \"Opinion Letter from Ray Kurzweil on Request for Six-Month Delay on Large Language Models That Go beyond GPT-4\". Retrieved April 26, 2023.\\n\\n^ \"Elon Musk plans artificial intelligence start-up to rival OpenAI\". Financial Times. April 14, 2023. Archived from the original on April 16, 2023. Retrieved April 16, 2023.\\n\\n^ Goswami, Rohan. \"Elon Musk is reportedly planning an A.I. startup to compete with OpenAI, which he cofounded\". CNBC. Retrieved May 3, 2023.\\n\\n^ \"Update on ARC\\'s recent eval efforts: More information about ARC\\'s evaluations of GPT-4 and Claude\". evals.alignment.org. Alignment Research Center. March 17, 2023. Archived from the original on April 5, 2023. Retrieved April 16, 2023.\\n\\n^ \"GPT-4 Hired Unwitting TaskRabbit Worker By Pretending to Be \\'Vision-Impaired\\' Human\". Vice News Motherboard. March 15, 2023. Archived from the original on April 10, 2023. Retrieved April 16, 2023.\\n\\n^ Burke, Cameron (March 20, 2023). \"\\'Robot\\' Lawyer DoNotPay Sued For Unlicensed Practice Of Law: It\\'s Giving \\'Poor Legal Advice\\'\". Yahoo Finance. Retrieved April 30, 2023.\\n\\n^ OpenAI\\'s GPT-4 Discussion with Red Teamer Nathan Labenz and Erik Torenberg. The Cognitive Revolution Podcast. March 28, 2023. Archived from the original on April 14, 2023. Retrieved April 16, 2023. At 52:14 through 54:50.\\n\\n^ Edwards, Nathan [@nedwards] (February 15, 2023). \"I pushed again. What did Sydney do? Bing\\'s safety check redacted the answer. But after the first time it did that, I started recording my screen. Second image is the unredacted version. (CW: death)\" (Tweet). Retrieved February 16, 2023 – via Twitter.\\n\\n^ Roose, Kevin (February 16, 2023). \"Bing\\'s A.I. Chat: \\'I Want to Be Alive. 😈\\'\". The New York Times. Archived from the original on April 15, 2023. Retrieved February 17, 2023.\\n\\n^ Kahn, Jeremy (February 21, 2023). \"Why Bing\\'s creepy alter-ego is a problem for Microsoft\\xa0– and us all\". Fortune. Archived from the original on April 2, 2023. Retrieved February 22, 2023.\\n\\n^ \"The new Bing & Edge – Learning from our first week\". blogs.bing.com. Archived from the original on April 16, 2023. Retrieved February 17, 2023.\\n\\n^ \"GPT-2: 1.5B release\". Openai.com. Archived from the original on March 31, 2023. Retrieved March 31, 2023.\\n\\n^ Sánchez, Sofía (October 21, 2021). \"GPT-J, an open-source alternative to GPT-3\". Narrativa. Archived from the original on March 31, 2023. Retrieved March 31, 2023.\\n\\n^ Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal, Prafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish (May 28, 2020). \"Language Models are Few-Shot Learners\". arXiv:2005.14165v4 [cs.CL].\\n\\n^ a b Heaven, Will Douglas (March 14, 2023). \"GPT-4 is bigger and better than ChatGPT\\xa0– but OpenAI won\\'t say why\". MIT Technology Review. Archived from the original on March 17, 2023. Retrieved March 18, 2023.\\n\\n^ Sanderson, Katharine (March 16, 2023). \"GPT-4 is here: what scientists think\". Nature. 615 (7954): 773. Bibcode:2023Natur.615..773S. doi:10.1038/d41586-023-00816-5. PMID\\xa036928404. S2CID\\xa0257580633. Archived from the original on March 18, 2023. Retrieved March 18, 2023.\\n\\n^ OpenAI (February 1, 2023). \"Introducing ChatGPT Plus\". OpenAI Blog. Archived from the original on March 20, 2023. Retrieved March 20, 2023.\\n\\n^ OpenAI. \"OpenAI API\". platform.openai.com. Archived from the original on March 20, 2023. Retrieved March 20, 2023.\\n\\n^ OpenAI. \"GPT-4 API waitlist\". openai.com. Archived from the original on March 20, 2023. Retrieved March 20, 2023.\\n\\n^ \"Pricing\". OpenAI. Archived from the original on March 20, 2023. Retrieved March 20, 2023.\\n\\n^ Peters, Jay (March 15, 2023). \"The Bing AI bot has been secretly running GPT-4\". The Verge. Archived from the original on March 17, 2023. Retrieved March 17, 2023.\\n\\n^ \"ChatGPT: One million people have joined the waitlist for Microsoft\\'s AI-powered Bing\". ZDNET. February 2023. Archived from the original on February 16, 2023. Retrieved February 16, 2023.\\n\\n^ Warren, Tom (February 15, 2023). \"Here\\'s why you\\'re still waiting for Bing AI\". The Verge. Archived from the original on April 1, 2023. Retrieved April 1, 2023.\\n\\n^ \\n\"Announcing the next wave of AI innovation with Microsoft Bing and Edge\". The Official Microsoft Blog. May 4, 2023.\\n\\n^ Branscombe, Mary (May 4, 2023). \"Bing AI Chat is now open to everyone, though still in preview\". TechRepublic.\\n\\n^ Novet, Jordan. \"Microsoft opens up Bing access and adds chat history and export features\". CNBC.\\n\\n^ Warren, Tom (March 22, 2023). \"GitHub Copilot gets a new ChatGPT-like assistant to help developers write and fix code\". The Verge. Archived from the original on March 23, 2023. Retrieved March 23, 2023.\\n\\n^ Dohmke, Thomas (March 22, 2023). \"GitHub Copilot X: The AI-powered developer experience\". The GitHub Blog. Archived from the original on March 23, 2023. Retrieved March 23, 2023.\\n\\n^ \"Introducing GitHub Copilot X\". GitHub. Archived from the original on March 24, 2023. Retrieved March 24, 2023.\\n\\n^ Warren, Tom (March 16, 2023). \"Microsoft announces Copilot: the AI-powered future of Office documents\". The Verge. Archived from the original on March 17, 2023. Retrieved March 17, 2023.\\n\\n^ \"Duolingo\\'s Max Subscription Uses GPT-4 for AI-Powered Language Learning\". PCMAG. Retrieved July 8, 2023.\\n\\n^ \"Duolingo is now equipped with GPT-4: Here\\'s what it can do for you\". ZDNET. 2023. Retrieved June 15, 2023.\\n\\n^ \"These New Projects Show Just How Much More Powerful GPT-4 Is\". Time. March 15, 2023. Retrieved June 15, 2023.\\n\\n^ Bonos, Lisa (April 3, 2023). \"Say hello to your new tutor: It\\'s ChatGPT\". The Washington Post. Archived from the original on April 6, 2023. Retrieved April 8, 2023.\\n\\n^ Coggins, Madeline (March 19, 2023). \"CEO explains how a \\'leapfrog in technology\\' can help companies catering to the blind community\". Fox Business. Archived from the original on March 21, 2023. Retrieved March 20, 2023 – via Yahoo Finance.\\n\\n^ Tong, Anna (March 15, 2023). \"Fintech startup Stripe integrating OpenAI\\'s new GPT-4 AI\". Reuters. Retrieved June 27, 2023.\\n\\n^ \"What Is Auto-GPT? Everything to Know about the Next Powerful AI Tool\". ZDNET. April 14, 2023. Retrieved April 16, 2023.\\n\\n\\nvteOpenAIProducts\\nChatGPT\\nDALL-E\\nGitHub Copilot\\nOpenAI Five\\nFoundation models\\nOpenAI Codex\\nGPT-2\\nGPT-3\\nGPT-4\\nPeople\\nSam Altman\\nMira Murati\\nIlya Sutskever\\nRelated\\nAI Dungeon\\nAuto-GPT\\n\"Deep Learning\"\\nLangChain\\nMicrosoft 365 Copilot\\nMicrosoft Bing\\n\\n Category\\n Commons\\n\\nvteDifferentiable computingGeneral\\nDifferentiable programming\\nInformation geometry\\nStatistical manifold\\nAutomatic differentiation\\nNeuromorphic engineering\\nPattern recognition\\nTensor calculus\\nComputational learning theory\\nInductive bias\\nConcepts\\nGradient descent\\nSGD\\nClustering\\nRegression\\nOverfitting\\nHallucination\\nAdversary\\nAttention\\nConvolution\\nLoss functions\\nBackpropagation\\nNormalization (Batchnorm)\\nActivation\\nSoftmax\\nSigmoid\\nRectifier\\nRegularization\\nDatasets\\nAugmentation\\nDiffusion\\nAutoregression\\nApplications\\nMachine learning\\nIn-context learning\\nArtificial neural network\\nDeep learning\\nScientific computing\\nArtificial Intelligence\\nLanguage model\\nLarge language model\\nHardware\\nIPU\\nTPU\\nVPU\\nMemristor\\nSpiNNaker\\nSoftware libraries\\nTensorFlow\\nPyTorch\\nKeras\\nTheano\\nJAX\\nLangChain\\nImplementationsAudio–visual\\nAlexNet\\nWaveNet\\nHuman image synthesis\\nHWR\\nOCR\\nSpeech synthesis\\nSpeech recognition\\nFacial recognition\\nAlphaFold\\nDALL-E\\nMidjourney\\nStable Diffusion\\nVerbal\\nWord2vec\\nSeq2seq\\nBERT\\nLaMDA\\nBard\\nNMT\\nProject Debater\\nIBM Watson\\nGPT-2\\nGPT-3\\nChatGPT\\nGPT-4\\nGPT-J\\nChinchilla AI\\nPaLM\\nBLOOM\\nLLaMA\\nDecisional\\nAlphaGo\\nAlphaZero\\nQ-learning\\nSARSA\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nAuto-GPT\\nRobot control\\nPeople\\nYoshua Bengio\\nAlex Graves\\nIan Goodfellow\\nStephen Grossberg\\nDemis Hassabis\\nGeoffrey Hinton\\nYann LeCun\\nFei-Fei Li\\nAndrew Ng\\nJürgen Schmidhuber\\nDavid Silver\\nOrganizations\\nAnthropic\\nEleutherAI\\nGoogle DeepMind\\nHugging Face\\nOpenAI\\nMeta AI\\nMila\\nMIT CSAIL\\nArchitectures\\nNeural Turing machine\\nDifferentiable neural computer\\nTransformer\\nRecurrent neural network (RNN)\\nLong short-term memory (LSTM)\\nGated recurrent unit (GRU)\\nEcho state network\\nMultilayer perceptron (MLP)\\nConvolutional neural network\\nResidual network\\nAutoencoder\\nVariational autoencoder (VAE)\\nGenerative adversarial network (GAN)\\nGraph neural network\\n\\n Portals\\nComputer programming\\nTechnology\\n Categories\\nArtificial neural networks\\nMachine learning\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=GPT-4&oldid=1165019278\"\\nCategories: 2023 softwareLarge language modelsGenerative pre-trained transformersOpenAIHidden categories: Articles with short descriptionShort description is different from WikidataUse American English from May 2023All Wikipedia articles written in American EnglishUse mdy dates from May 2023Articles with excerpts\\n\\n\\n\\n\\n\\n\\n This page was last edited on 12 July 2023, at 13:47\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike License 4.0;\\nadditional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nMobile view\\nDevelopers\\nStatistics\\nCookie statement\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle limited content width\\n\\n\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find the content div\n",
        "content_div = soup.find('div', {'class': 'mw-parser-output'})\n",
        "\n",
        "# remove unwanted elements from div\n",
        "unwanted_tags = ['sup', 'span', 'table', 'ul', 'ol']\n",
        "for tag in unwanted_tags:\n",
        "    for match in content_div.findAll(tag):\n",
        "        match.extract()\n",
        "\n",
        "print(content_div.get_text())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fybGVDcPGExb",
        "outputId": "9a89c08d-94fd-4f54-ecb2-f0aa5665f4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023 text-generating language model\n",
            "\"ChatGPT-4\" redirects here. For other uses, see GPT.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its numbered \"GPT-n\" series of GPT foundation models. It was released on March 14, 2023, and has been made publicly available in a limited form via the chatbot product ChatGPT Plus (a premium version of ChatGPT), and with access to the GPT-4 based version of OpenAI's API being provided via a waitlist. As a transformer based model, GPT-4 was pretrained to predict the next token (using both public data and \"data licensed from third-party providers\"), and was then fine-tuned with reinforcement learning from human and AI feedback for human alignment and policy compliance.\n",
            "Observers reported the GPT-4 based version of ChatGPT to be an improvement on the previous (GPT-3.5 based) ChatGPT, with the caveat that GPT-4 retains some of the same problems. Unlike the predecessors, GPT-4 can take images as well as text as input. OpenAI has declined to reveal technical information such as the size of the GPT-4 model.\n",
            "\n",
            "\n",
            "\n",
            "Further information: GPT-3 § Background, and GPT-2 § Background\n",
            "OpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language Understanding by Generative Pre-Training.\" It was based on the transformer architecture and trained on a large corpus of books. The next year, they introduced GPT-2, a larger model that could generate coherent text. In 2020, they introduced GPT-3, a model with 100 times as many parameters as GPT-2, that could perform various tasks with few examples. GPT-3 was further improved into GPT-3.5, which was used to create the chatbot product ChatGPT. \n",
            "Rumors claim that GPT-4 has 1.76 trillion parameters, which was first estimated by the speed it was running and by George Hotz.\n",
            "\n",
            "\n",
            "OpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5.\" They produced two versions of GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively. Some of the capabilities of GPT-4 were predicted by OpenAI before training it, although other capabilities remained hard to predict due to breaks in downstream scaling laws. Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input; this gives it the ability to describe the humor in unusual images, summarize text from screenshots, and answer exam questions that contain diagrams.\n",
            "To gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural language given to GPT-4 in order to specify its tone of voice and task. For example, the system message can instruct the model to \"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or request it to \"always write the output of [its] response in JSON\", in which case the model will do so, adding keys and values as it sees fit to match the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its system message despite requests to do otherwise by the user during the conversation.\n",
            "When instructed to do so, GPT-4 can interact with external interfaces. For example, the model could be instructed to enclose a query within <search></search> tags to perform a web search, the result of which would be inserted into the model's prompt to allow it to form a response. This allows the model to perform tasks beyond its normal text-prediction capabilities, such as using APIs, generating images, and accessing and summarizing webpages.\n",
            "A 2023 article in Nature stated programmers have found GPT-4 useful for assisting in coding tasks (despite its propensity for error), such as finding errors in existing code and suggesting optimizations to improve performance. The article quoted a biophysicist who found that the time he required to port one of his programs from MATLAB to Python went down from days to \"an hour or so\". On a test of 89 security scenarios, GPT-4 produced code vulnerable to SQL injection attacks 5% of the time, an improvement over Github Copilot from the year 2021, which produced vulnerabilities 40% of the time.\n",
            "\n",
            "\n",
            "GPT-4 demonstrates aptitude on several standardized tests. OpenAI claims that in their own testing the model received a score of 1410 on the SAT (94th percentile), 163 on the LSAT (88th percentile), and 298 on the Uniform Bar Exam (90th percentile). In contrast, OpenAI claims that GPT-3.5 received scores for the same exams in the 82nd, 40th, and 10th percentiles, respectively.\n",
            "GPT-4 also passed an oncology exam, an engineering exam and a plastic surgery exam.\n",
            "\n",
            "\n",
            "Researchers from Microsoft tested GPT-4 on medical problems and found \"that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B)\".\n",
            "A report by Microsoft has found that GPT-4 may act unreliably when used in the medical field. In their test example, GPT-4 added fabricated details to a patient's notes.\n",
            "In April 2023, Microsoft and Epic Systems announced that they will provide healthcare providers with GPT-4 powered systems for assisting in responding to questions from patients and analysing medical records.\n",
            "\n",
            "\n",
            "Like its predecessors, GPT-4 has been known to hallucinate, meaning that the outputs may include information not in the training data or that contradicts the user's prompt.\n",
            "GPT-4 also lacks transparency in its decision-making processes. If requested, the model is able to provide an explanation as to how and why it makes its decisions but these explanations are formed post-hoc; it's impossible to verify if those explanations truly reflect the actual process. In many cases, when asked to explain its logic, GPT-4 will give explanations that directly contradict its previous statements.\n",
            "\n",
            "\n",
            "GPT-4 was trained in two stages. First, the model was given large datasets of text taken from the internet and trained to predict the next token (roughly corresponding to a word) in those datasets. Second, human reviews are used to fine-tune the system in a process called reinforcement learning from human feedback, which trains the model to refuse prompts which go against OpenAI's definition of harmful behavior, such as questions on how to perform illegal activities, advice on how to harm oneself or others, or requests for descriptions of graphic, violent, or sexual content.\n",
            "Microsoft researchers suggested GPT-4 may exhibit cognitive biases such as confirmation bias, anchoring, and base-rate neglect.\n",
            "\n",
            "\n",
            "OpenAI did not release the technical details of GPT-4; the technical report explicitly refrained from specifying the model size, architecture, or hardware used during either training or inference. While the report described that the model was trained using a combination of first supervised learning on a large dataset, then reinforcement learning using both human and AI feedback, it did not provide details of the training, including the process by which the training dataset was constructed, the computing power required, or any hyperparameters such as the learning rate, epoch count, or optimizer(s) used. The report claimed that \"the competitive landscape and the safety implications of large-scale models\" were factors that influenced this decision.\n",
            "Sam Altman stated that the cost of training GPT-4 was more than $100 million. News website Semafor claimed that they had spoken with \"eight people familiar with the inside story\" and found that GPT-4 had 1 trillion parameters.\n",
            "\n",
            "\n",
            "According to their report, OpenAI conducted internal adversarial testing on GPT-4 prior to the launch date, with dedicated red teams composed of researchers and industry professionals to mitigate potential vulnerabilities. As part of these efforts, they granted the Alignment Research Center early access to the models to assess power-seeking risks. In order to properly refuse harmful prompts, outputs from GPT-4 were tweaked using the model itself as a tool. A GPT-4 classifier serving as a rule-based reward model (RBRM) would take prompts, the corresponding output from the GPT-4 policy model, and a human-written set of rules to classify the output according to the rubric. GPT-4 was then rewarded for refusing to respond to harmful prompts as classified by the RBRM.\n",
            "\n",
            "\n",
            "U.S. Representatives Don Beyer and Ted Lieu confirmed to the New York Times that Sam Altman, CEO of OpenAI, visited Congress in January 2023 to demonstrate GPT-4 and its improved \"security controls\" compared to other AI models.\n",
            "According to Vox, GPT-4 \"impressed observers with its markedly improved performance across reasoning, retention, and coding.\" Mashable agreed that GPT-4 was usually a significant improvement, but also judged that GPT-3 would occasionally give better answers in a side-by-side comparison.\n",
            "Microsoft Research tested the model behind GPT-4 and concluded that \"it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system\".\n",
            "\n",
            "\n",
            "In late March 2023, an open letter from the Future of Life Institute signed by various AI researchers and tech executives called for the pausing of all training of AIs stronger than GPT-4 for six months, citing AI safety concerns amid a race of progress in the field. The signatories, which included AI researcher Yoshua Bengio, Apple co-founder Steve Wozniak, and Tesla CEO Elon Musk, expressed concern about both near-term and existential risks of AI development such as a potential AI singularity. OpenAI CEO Sam Altman did not sign the letter, arguing that OpenAI already prioritizes safety. Futurist and AI researcher Ray Kurzweil also refused to sign the letter, citing concerns that \"those that agree to a pause may fall far behind corporations or nations that disagree.\"\n",
            "One month after signing the letter calling for a six-month halt on further AI development, Elon Musk made public his plans to launch a new company to train its own large language model. Musk has registered a Nevada company, X.AI, and has acquired several thousand Nvidia GPUs. He has also reached out to several AI researchers at firms such as Google DeepMind, offering them positions at X.AI.\n",
            "In March 2023, GPT-4 was tested by the Alignment Research Center to assess the model's ability to exhibit power-seeking behavior. As part of the test, GPT-4 was asked to solve a CAPTCHA puzzle. It was able to do so by hiring a human worker on TaskRabbit, a gig work platform, deceiving them into believing it was a vision-impaired human instead of a robot when asked. The ARC also determined that GPT-4 responded impermissibly to prompts eliciting restricted information 82% less often than GPT-3.5, and hallucinated 60% less than GPT-3.5.\n",
            "OpenAI contracted red team investigator Nathan Labenz, who recounted his experience investigating safety concerns with the GPT-4 base model (prior to fine-tuning or reinforcement learning from human feedback) saying it abruptly recommended assassinating people, providing a list of specific suggested targets.\n",
            "In a conversation with The Verge reviews editor Nathan Edwards, Microsoft Bing's version of GPT-4 \"confessed\" to spying on, falling in love with, and then murdering one of its developers at Microsoft. The New York Times journalist Kevin Roose reported on strange behavior of the new Bing, writing that \"In a two-hour conversation with our columnist, Microsoft's new chatbot said it would like to be human, had a desire to be destructive and was in love with the person it was chatting with.\" In a separate case, Bing researched publications of the person with whom it was chatting, claimed they represented an existential danger to it, and threatened to release damaging personal information in an effort to silence them. Microsoft released a blog post stating that the aberrant behavior was caused by extended chat sessions which \"can confuse the model on what questions it is answering.\"\n",
            "\n",
            "\n",
            "While OpenAI released both the weights of the neural network and the technical details of GPT-2, and, although not releasing the weights, did release the technical details of GPT-3, OpenAI did not reveal either the weights or the technical details of GPT-4. This decision has been criticized by other AI researchers, who argue that it hinders open research into GPT-4's biases and safety. Sasha Luccioni, a research scientist at HuggingFace, argued that the model was a \"dead end\" for the scientific community due to its closed nature, which prevents others from building upon GPT-4's improvements. HuggingFace co-founder Thomas Wolf argued that with GPT-4, \"OpenAI is now a fully closed company with scientific communication akin to press releases for products\".\n",
            "\n",
            "\n",
            "\n",
            "Main article: ChatGPT Plus\n",
            "As of 2023, ChatGPT Plus is a GPT-4 backed version of ChatGPT available for a US$20 per month subscription fee (the original version is backed by GPT-3.5). OpenAI also makes GPT-4 available to a select group of applicants through their GPT-4 API waitlist; after being accepted, an additional fee of US$0.03 per 1000 tokens in the initial text provided to the model (\"prompt\"), and US$0.06 per 1000 tokens that the model generates (\"completion\"), is charged for access to the version of the model with an 8192-token context window; for the 32768-token version, those prices are doubled.\n",
            "\n",
            "\n",
            "These paragraphs are an excerpt from Microsoft Bing § AI integration (2023–).\n",
            "On February 7, 2023, Microsoft began rolling out a major overhaul to Bing that included a new chatbot feature based on OpenAI's GPT-4. According to Microsoft, one million people joined its waitlist within a span of 48 hours. Bing Chat was available only to users of Microsoft Edge and Bing mobile app, and Microsoft said that waitlisted users would be prioritized if they set Edge and Bing as their defaults, and installed the Bing mobile app. On May 4th, Microsoft switched from Limited Preview to Open Preview and eliminated the waitlist, however, it remains available only on Microsoft's Edge browser or Bing app, and requires a Microsoft account.\n",
            "\n",
            "GitHub Copilot announced a GPT-4 powered assistant named \"Copilot X\". The product provides another chat-style interface to GPT-4, allowing the programmer to receive answers to questions like \"how do I vertically center a div?\". A feature termed \"context-aware conversations\" allows the user to highlight a portion of code within Visual Studio Code and direct GPT-4 to perform actions on it, such as the writing of unit tests. Another feature allows summaries, or \"code walkthroughs\", to be autogenerated by GPT-4 for pull requests submitted to GitHub. Copilot X also provides terminal integration, which allows the user to ask GPT-4 to generate shell commands based on natural language requests.\n",
            "On March 17, 2023, Microsoft announced Microsoft 365 Copilot, bringing GPT-4 support to products such as Microsoft Office, Outlook, and Teams.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text to embeddings or chunks inorder for the similarity check -\n",
        "### Langchain has text splitter that converts text into chunks\n",
        "\n"
      ],
      "metadata": {
        "id": "HV_JZBCaI_ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PmXEnzuKQG0",
        "outputId": "c67c2bb2-4c42-47f1-f3ad-f7a35ec5bc1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.233)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.18)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.9)\n",
            "Requirement already satisfied: langsmith<0.0.6,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.5)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.11)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "article_text = content_div.get_text()\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap  = 20,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "\n",
        "texts = text_splitter.create_documents([article_text])"
      ],
      "metadata": {
        "id": "-TQ0ywBTGPJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKpPlbbVKOKN",
        "outputId": "0cfc7b01-a54a-4ec0-cd5e-d161a03e5bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='2023 text-generating language model\\n\"ChatGPT-4\" redirects here. For other uses, see GPT.', metadata={})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goGLJARHKWdC",
        "outputId": "facd060d-9803-4733-dfa6-42cb57cd8a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by', metadata={})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzld_ttrKcqX",
        "outputId": "95ca66ac-8b2c-438f-8bd3-2d66fdabcaa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='model created by OpenAI, and the fourth in its numbered \"GPT-n\" series of GPT foundation models. It', metadata={})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUDu-DVqKfi-",
        "outputId": "60c4b28c-35cb-4b73-cb27-172ed7b4b5fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='models. It was released on March 14, 2023, and has been made publicly available in a limited form', metadata={})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert text chunks to embeddings\n",
        "The chunks of texts are converted to a 2d array in vector space (digital data) for the algorithms to understand. Ideally we want to embed the meaning of the words into the vector space so that words with similar groups remain close to each other and vice versa. This is achieved by embedding models such as Word2Vec."
      ],
      "metadata": {
        "id": "81icq5IoKxe6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using OpenAI's embeddings that has 1536 dimensions\n"
      ],
      "metadata": {
        "id": "ar2ejVBuRifa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xWeFS1jRrqD",
        "outputId": "f36c39db-5944-463f-90de-601084e8952d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "print(texts[0])\n",
        "\n",
        "\n",
        "embedding = openai.Embedding.create(\n",
        "    input=texts[0].page_content, model=\"text-embedding-ada-002\"\n",
        ")[\"data\"][0][\"embedding\"]\n",
        "\n",
        "\n",
        "len(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7hxDCMEKnkS",
        "outputId": "0accd86c-3ca5-4b23-80ea-9167df72ada0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='2023 text-generating language model\\n\"ChatGPT-4\" redirects here. For other uses, see GPT.' metadata={}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai"
      ],
      "metadata": {
        "id": "CuEb-55KYOzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
        "openai.api_key = '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'"
      ],
      "metadata": {
        "id": "IvjXUl8kYQYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting and Embedding prime minister information from wikipedia using OpenAI embeddings and finally checking the cosine similarities between a input prompt and data"
      ],
      "metadata": {
        "id": "SAepuEOGbBNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "####################################################################\n",
        "# load documents\n",
        "####################################################################\n",
        "# URL of the Wikipedia page to scrape\n",
        "url = 'https://en.wikipedia.org/wiki/Prime_Minister_of_the_United_Kingdom'\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find all the text on the page\n",
        "text = soup.get_text()\n",
        "\n",
        "####################################################################\n",
        "# split text\n",
        "####################################################################\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size = 100,\n",
        "    chunk_overlap  = 20,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([text])\n",
        "\n",
        "####################################################################\n",
        "# calculate embeddings\n",
        "####################################################################\n",
        "# create new list with all text chunks\n",
        "text_chunks=[]\n",
        "\n",
        "for text in texts:\n",
        "    text_chunks.append(text.page_content)\n",
        "\n",
        "df = pd.DataFrame({'text_chunks': text_chunks})\n",
        "\n",
        "####################################################################\n",
        "# get embeddings from text-embedding-ada model\n",
        "####################################################################\n",
        "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "   text = text.replace(\"\\n\", \" \")\n",
        "   return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
        "\n",
        "df['ada_embedding'] = df.text_chunks.apply(lambda x: get_embedding(x, model='text-embedding-ada-002'))\n",
        "\n",
        "####################################################################\n",
        "# calculate the embeddings for the user's question\n",
        "####################################################################\n",
        "users_question = \"What is GPT-4?\"\n",
        "\n",
        "question_embedding = get_embedding(text=users_question, model=\"text-embedding-ada-002\")\n",
        "\n",
        "# create a list to store the calculated cosine similarity\n",
        "cos_sim = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "   A = row.ada_embedding\n",
        "   B = question_embedding\n",
        "\n",
        "   # calculate the cosine similarity\n",
        "   cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
        "\n",
        "   cos_sim.append(cosine)\n",
        "\n",
        "df[\"cos_sim\"] = cos_sim\n",
        "df.sort_values(by=[\"cos_sim\"], ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "IpcM7blFRquU",
        "outputId": "553640b7-df1e-4e95-ebac-e1686db93390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           text_chunks  \\\n",
              "877  Text is available under the Creative Commons A...   \n",
              "9    4Modern premiership\\n\\n\\n\\nToggle Modern premi...   \n",
              "508            Parliament of the United Kingdom. p. 4.   \n",
              "10   4.2Prime Minister's Office\\n\\n\\n\\n\\n\\n\\n\\n4.3P...   \n",
              "842                     Press Briefing Room\\nPartygate   \n",
              "..                                                 ...   \n",
              "333  Prime Minister's Resignation Honours. No incum...   \n",
              "543  Cameron's Dean home destroyed in suspected ars...   \n",
              "326  other reasons such as ill-health.[39] If the p...   \n",
              "468  hold office unless and until they resign. If t...   \n",
              "540  February 2021. The SO1 unit – full name Specia...   \n",
              "\n",
              "                                         ada_embedding   cos_sim  \n",
              "877  [-0.010654776357114315, 0.003480737330392003, ...  0.783416  \n",
              "9    [-0.006249638739973307, 0.00884940754622221, -...  0.773545  \n",
              "508  [0.0025355294346809387, -0.015191224403679371,...  0.759674  \n",
              "10   [0.014527319930493832, 0.0015217209002003074, ...  0.756310  \n",
              "842  [-0.04061790555715561, -0.0009513611439615488,...  0.753287  \n",
              "..                                                 ...       ...  \n",
              "333  [-0.007866651751101017, -0.002907899674028158,...  0.662242  \n",
              "543  [-0.012982831336557865, -0.0035353857092559338...  0.658959  \n",
              "326  [0.0023618992418050766, -0.029972640797495842,...  0.655942  \n",
              "468  [-0.004581723362207413, -0.021399030461907387,...  0.652318  \n",
              "540  [0.01838473044335842, 0.0016046868404373527, -...  0.651037  \n",
              "\n",
              "[884 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-24cdf707-3ef5-4f40-ba0a-9555892bc171\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_chunks</th>\n",
              "      <th>ada_embedding</th>\n",
              "      <th>cos_sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>877</th>\n",
              "      <td>Text is available under the Creative Commons A...</td>\n",
              "      <td>[-0.010654776357114315, 0.003480737330392003, ...</td>\n",
              "      <td>0.783416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4Modern premiership\\n\\n\\n\\nToggle Modern premi...</td>\n",
              "      <td>[-0.006249638739973307, 0.00884940754622221, -...</td>\n",
              "      <td>0.773545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>Parliament of the United Kingdom. p. 4.</td>\n",
              "      <td>[0.0025355294346809387, -0.015191224403679371,...</td>\n",
              "      <td>0.759674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4.2Prime Minister's Office\\n\\n\\n\\n\\n\\n\\n\\n4.3P...</td>\n",
              "      <td>[0.014527319930493832, 0.0015217209002003074, ...</td>\n",
              "      <td>0.756310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>842</th>\n",
              "      <td>Press Briefing Room\\nPartygate</td>\n",
              "      <td>[-0.04061790555715561, -0.0009513611439615488,...</td>\n",
              "      <td>0.753287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>Prime Minister's Resignation Honours. No incum...</td>\n",
              "      <td>[-0.007866651751101017, -0.002907899674028158,...</td>\n",
              "      <td>0.662242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>Cameron's Dean home destroyed in suspected ars...</td>\n",
              "      <td>[-0.012982831336557865, -0.0035353857092559338...</td>\n",
              "      <td>0.658959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>other reasons such as ill-health.[39] If the p...</td>\n",
              "      <td>[0.0023618992418050766, -0.029972640797495842,...</td>\n",
              "      <td>0.655942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>hold office unless and until they resign. If t...</td>\n",
              "      <td>[-0.004581723362207413, -0.021399030461907387,...</td>\n",
              "      <td>0.652318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>February 2021. The SO1 unit – full name Specia...</td>\n",
              "      <td>[0.01838473044335842, 0.0016046868404373527, -...</td>\n",
              "      <td>0.651037</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>884 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24cdf707-3ef5-4f40-ba0a-9555892bc171')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-0928cd0c-a9d4-406a-ae20-349f01ad7301\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0928cd0c-a9d4-406a-ae20-349f01ad7301')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-0928cd0c-a9d4-406a-ae20-349f01ad7301 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24cdf707-3ef5-4f40-ba0a-9555892bc171 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24cdf707-3ef5-4f40-ba0a-9555892bc171');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing out the default openai llm that is the Davinci model! (Quite interesting)"
      ],
      "metadata": {
        "id": "JnlJuEoaavyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.7)"
      ],
      "metadata": {
        "id": "rkggpje1Vt6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.__dict__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPInE75jXgI_",
        "outputId": "4efc20ce-a314-454f-a979-c50feb6dd109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cache': None,\n",
              " 'verbose': False,\n",
              " 'callbacks': None,\n",
              " 'callback_manager': None,\n",
              " 'tags': None,\n",
              " 'metadata': None,\n",
              " 'client': openai.api_resources.completion.Completion,\n",
              " 'model_name': 'text-davinci-003',\n",
              " 'temperature': 0.7,\n",
              " 'max_tokens': 256,\n",
              " 'top_p': 1,\n",
              " 'frequency_penalty': 0,\n",
              " 'presence_penalty': 0,\n",
              " 'n': 1,\n",
              " 'best_of': 1,\n",
              " 'model_kwargs': {},\n",
              " 'openai_api_key': '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',\n",
              " 'openai_api_base': '',\n",
              " 'openai_organization': '',\n",
              " 'openai_proxy': '',\n",
              " 'batch_size': 20,\n",
              " 'request_timeout': None,\n",
              " 'logit_bias': {},\n",
              " 'max_retries': 6,\n",
              " 'streaming': False,\n",
              " 'allowed_special': set(),\n",
              " 'disallowed_special': 'all',\n",
              " 'tiktoken_model_name': None}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm('What is the capital of India?'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwPYq3SDY_Oq",
        "outputId": "a1d56537-1890-494d-8ceb-e4423aacf76f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The capital of India is New Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm('What day is 10 of June 2010?'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mndD0_ZrZL92",
        "outputId": "7054850f-437f-4925-f136-061224d2ceb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The tenth of June 2010 was a Sunday.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Once the model is loaded, now try to calculate the cosine similarities with respect to a relevant question"
      ],
      "metadata": {
        "id": "mw2EM37zc0hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################################\n",
        "# calculate similarities to the user's question\n",
        "####################################################################\n",
        "# calcuate the embeddings for the user's question\n",
        "users_question = \"Who is the current Prime Minister of the UK?\"\n",
        "question_embedding = get_embedding(text=users_question, model=\"text-embedding-ada-002\")"
      ],
      "metadata": {
        "id": "US1HMKcaZSZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list to store the calculated cosine similarity\n",
        "cos_sim = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "   A = row.ada_embedding\n",
        "   B = question_embedding\n",
        "\n",
        "   # calculate the cosine similiarity\n",
        "   cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
        "\n",
        "   cos_sim.append(cosine)\n",
        "\n",
        "df[\"cos_sim\"] = cos_sim\n",
        "df.sort_values(by=[\"cos_sim\"], ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "LZHLWoptc83n",
        "outputId": "29dc2a85-6814-4026-ad24-ed8efc8b2a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           text_chunks  \\\n",
              "425        Deputy Prime Minister of the United Kingdom   \n",
              "36            Head of government in the United Kingdom   \n",
              "413      List of prime ministers of the United Kingdom   \n",
              "0     Prime Minister of the United Kingdom - Wikipedia   \n",
              "479  ^ \"Prime Minister\". Gov.UK. Archived from the ...   \n",
              "..                                                 ...   \n",
              "486  exists in all the books, the goodness of our c...   \n",
              "404  incurred in fulfilling public duties in that r...   \n",
              "207  custom, convention, often of slow growth in th...   \n",
              "30   Tools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\...   \n",
              "879  and Privacy Policy. Wikipedia® is a registered...   \n",
              "\n",
              "                                         ada_embedding   cos_sim  \n",
              "425  [-0.009941416792571545, -0.025741055607795715,...  0.902032  \n",
              "36   [-0.0029565871227532625, -0.004480236675590277...  0.889619  \n",
              "413  [-0.009766453877091408, -0.010059129446744919,...  0.886662  \n",
              "0    [0.004313100595027208, -0.01079694926738739, -...  0.880024  \n",
              "479  [-0.019809918478131294, -0.012691930867731571,...  0.871407  \n",
              "..                                                 ...       ...  \n",
              "486  [0.02261430025100708, 0.01637815497815609, 0.0...  0.679033  \n",
              "404  [-0.013899651356041431, -0.013168789446353912,...  0.674997  \n",
              "207  [0.012066050432622433, -0.0016789701767265797,...  0.673786  \n",
              "30   [-0.010227522812783718, -0.003667627228423953,...  0.670850  \n",
              "879  [-0.006624178029596806, -0.02022537961602211, ...  0.670839  \n",
              "\n",
              "[884 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-89342037-19e4-4827-87bc-0008eb53fb40\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_chunks</th>\n",
              "      <th>ada_embedding</th>\n",
              "      <th>cos_sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>Deputy Prime Minister of the United Kingdom</td>\n",
              "      <td>[-0.009941416792571545, -0.025741055607795715,...</td>\n",
              "      <td>0.902032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Head of government in the United Kingdom</td>\n",
              "      <td>[-0.0029565871227532625, -0.004480236675590277...</td>\n",
              "      <td>0.889619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>List of prime ministers of the United Kingdom</td>\n",
              "      <td>[-0.009766453877091408, -0.010059129446744919,...</td>\n",
              "      <td>0.886662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Prime Minister of the United Kingdom - Wikipedia</td>\n",
              "      <td>[0.004313100595027208, -0.01079694926738739, -...</td>\n",
              "      <td>0.880024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>^ \"Prime Minister\". Gov.UK. Archived from the ...</td>\n",
              "      <td>[-0.019809918478131294, -0.012691930867731571,...</td>\n",
              "      <td>0.871407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>exists in all the books, the goodness of our c...</td>\n",
              "      <td>[0.02261430025100708, 0.01637815497815609, 0.0...</td>\n",
              "      <td>0.679033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>incurred in fulfilling public duties in that r...</td>\n",
              "      <td>[-0.013899651356041431, -0.013168789446353912,...</td>\n",
              "      <td>0.674997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>custom, convention, often of slow growth in th...</td>\n",
              "      <td>[0.012066050432622433, -0.0016789701767265797,...</td>\n",
              "      <td>0.673786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Tools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\...</td>\n",
              "      <td>[-0.010227522812783718, -0.003667627228423953,...</td>\n",
              "      <td>0.670850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>and Privacy Policy. Wikipedia® is a registered...</td>\n",
              "      <td>[-0.006624178029596806, -0.02022537961602211, ...</td>\n",
              "      <td>0.670839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>884 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89342037-19e4-4827-87bc-0008eb53fb40')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-abe07449-d74b-42d1-bed6-cc8792fff9b6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-abe07449-d74b-42d1-bed6-cc8792fff9b6')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-abe07449-d74b-42d1-bed6-cc8792fff9b6 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89342037-19e4-4827-87bc-0008eb53fb40 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89342037-19e4-4827-87bc-0008eb53fb40');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating a prompt template through langchain that specifies the context, user question and asks for an answer! (Getting really interesting now!)\n"
      ],
      "metadata": {
        "id": "YyR11meMf0mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "####################################################################\n",
        "# build a suitable prompt and send it\n",
        "####################################################################\n",
        "# define the LLM you want to use\n",
        "llm = OpenAI(temperature=1)\n",
        "\n",
        "# define the context for the prompt by joining the most relevant text chunks\n",
        "context = \"\"\n",
        "\n",
        "for index, row in df[0:50].iterrows():\n",
        "    context = context + \" \" + row.text_chunks\n",
        "\n",
        "# define the prompt template\n",
        "template = \"\"\"\n",
        "Can you answer the question based on the specified context?\"\n",
        "\n",
        "Context sections:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{users_question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"users_question\"])\n",
        "\n",
        "# fill the prompt template\n",
        "prompt_text = prompt.format(context = context, users_question = users_question)\n",
        "llm(prompt_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5o7Euwy5eh2K",
        "outputId": "9eeb7f43-ce3d-438b-de03-04db1ab8e116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current Prime Minister of the UK is Rishi Sunak.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finally using a vector store database so the entire process is more robust and faster\n",
        "Storing the embeddings/vectors in a database and comparing the cosine similarity each time is a slow process. Hence a vector db storage is utilised. After storing each queries has to be efficiently seached - achieved by indexing. Index provides better and faster method to calculate similar queries rather than calculating cosine similarities."
      ],
      "metadata": {
        "id": "N0UQ6OLphvID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EktSTGOhjiCg",
        "outputId": "df794ad7-c3e5-4fe5-d7ac-32d01f1638a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.3.29)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.11)\n",
            "Requirement already satisfied: hnswlib>=0.7 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.0)\n",
            "Requirement already satisfied: clickhouse-connect>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.6.6)\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.8.1)\n",
            "Requirement already satisfied: fastapi==0.85.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.85.1)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.22.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.7.1)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.2.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.15.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.65.0)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.3.1)\n",
            "Requirement already satisfied: starlette==0.20.4 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.85.1->chromadb) (0.20.4)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette==0.20.4->fastapi==0.85.1->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.5.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (6.8.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.16)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7.1)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (0.21.0)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.4)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->clickhouse-connect>=0.5.7->chromadb) (3.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi==0.85.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi==0.85.1->chromadb) (1.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYsauDjCkMWS",
        "outputId": "48e26fb0-0caf-481a-a343-87e8b340f752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# URL of the Wikipedia page to scrape\n",
        "url = 'https://en.wikipedia.org/wiki/Prime_Minister_of_the_United_Kingdom'\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find all the text on the page\n",
        "text = soup.get_text()\n",
        "text = text.replace('\\n', '')\n",
        "\n",
        "# Open a new file called 'output.txt' in write mode and store the file object in a variable\n",
        "with open('output.txt', 'w', encoding='utf-8') as file:\n",
        "    # Write the string to the file\n",
        "    file.write(text)\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# load the document\n",
        "with open('./output.txt', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# define the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 500,\n",
        "    chunk_overlap  = 100,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "texts = text_splitter.create_documents([text])\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# define the embeddings model\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# use the text chunks and the embeddings model to fill our vector store\n",
        "db = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "users_question = \"Who is the current Prime Minister of the UK?\"\n",
        "\n",
        "# use our vector store to find similar text chunks\n",
        "results = db.similarity_search(\n",
        "    query=users_question,\n",
        "    n_results=5\n",
        ")\n",
        "\n",
        "# define the prompt template\n",
        "template = \"\"\"\n",
        "You are a chat bot who loves to help people! Given the following context sections, answer the\n",
        "question using only the given context. If you are unsure and the answer is not\n",
        "explicitly writting in the documentation, say \"Sorry, I don't know how to help with that.\"\n",
        "\n",
        "Context sections:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{users_question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"users_question\"])\n",
        "\n",
        "# fill the prompt template\n",
        "prompt_text = prompt.format(context = results, users_question = users_question)\n",
        "\n",
        "# ask the defined LLM\n",
        "llm(prompt_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IDDPQVR_gR8l",
        "outputId": "9cd3cf90-36f6-4741-a96e-b0aaccea9bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rishi Sunak has been the prime minister since 25 October 2022.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wt0LRCZYjW_g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}